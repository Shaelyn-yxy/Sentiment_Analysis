{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if you want to see more details in grid search, you need to replace some parameters.Otherwise, just run all the code and 2 prediction file will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# optimize parameters\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading & Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv file\n",
    "text_train = pd.read_csv(\"review_text_train.csv\")\n",
    "meta_train = pd.read_csv(\"review_meta_train.csv\")\n",
    "labels = meta_train.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "sparse_train_raw = sparse.load_npz('review_text_features_countvec/review_text_train_vec.npz')\n",
    "sparse_test_raw = sparse.load_npz('review_text_features_countvec/review_text_test_vec.npz')\n",
    "doc2vec_50 = pd.read_csv(r\"review_text_features_doc2vec50/review_text_train_doc2vec50.csv\", index_col = False, delimiter = ',', header=None)\n",
    "doc2vec_100 = pd.read_csv(r\"review_text_features_doc2vec100/review_text_train_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "doc2vec_200 = pd.read_csv(r\"review_text_features_doc2vec200/review_text_train_doc2vec200.csv\", index_col = False, delimiter = ',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test split\n",
    "# split training data into training sets and validation sets\n",
    "sparse_train, sparse_val, sparse_label_train, sparse_label_val = train_test_split(sparse_train_raw,labels,test_size=0.3,random_state=17)\n",
    "\n",
    "d2v_50_train, d2v_50_val, d2v_50_label_train, d2v_50_label_val = train_test_split(doc2vec_50,labels,test_size=0.3,random_state=17)\n",
    "d2v_100_train, d2v_100_val, d2v_100_label_train, d2v_100_label_val = train_test_split(doc2vec_100,labels,test_size=0.3,random_state=17)\n",
    "d2v_200_train, d2v_200_val, d2v_200_label_train, d2v_200_label_val = train_test_split(doc2vec_200,labels,test_size=0.3,random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 One-R model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy of 0-R: 0.7007481296758105\n"
     ]
    }
   ],
   "source": [
    "one_r = DecisionTreeClassifier(max_depth=1)\n",
    "one_r.fit(sparse_train, sparse_label_train)\n",
    "one_r_acc = one_r.score(sparse_val, sparse_label_val)\n",
    "print(\"Accuarcy of 0-R:\",one_r_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Naive Bayse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use simple model to understand the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.902427851580394\n",
      "validation accuracy 0.8375489846811542\n"
     ]
    }
   ],
   "source": [
    "#  MultinomialNB performance on sparse matrix\n",
    "MNB_sp =  MultinomialNB().fit(sparse_train, sparse_label_train)\n",
    "print(\"Train accuracy:\", MNB_sp.score(sparse_train, sparse_label_train))\n",
    "print(\"validation accuracy\", MNB_sp.score(sparse_val, sparse_label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7267776250827098\n",
      "validation accuracy 0.7211732573328583\n"
     ]
    }
   ],
   "source": [
    "#  MultinomialNB performance on d2v matrix\n",
    "MNB_d2v = GaussianNB().fit(d2v_50_train, d2v_50_label_train)\n",
    "print(\"Train accuracy:\", MNB_d2v.score(d2v_50_train, d2v_50_label_train))\n",
    "print(\"validation accuracy\",MNB_d2v.score(d2v_50_val, d2v_50_label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train accuracy: 0.8228229055558037\n",
      "validation accuracy: 0.8310176938605867\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC with default paramenters\n",
    "sgd = SGDClassifier(loss='hinge', random_state=17)\n",
    "sgd.fit(sparse_train, sparse_label_train)\n",
    "print(\"Avg train accuracy:\", cross_val_score(sgd, sparse_train, sparse_label_train, cv=5).mean())\n",
    "print(\"validation accuracy:\", sgd.score(sparse_val, sparse_label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the code of classification example in sklearn document:\n",
    "<br>\n",
    "'https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline: ['tfidf', 'kbest', 'sgd']\n",
      "parameters:\n",
      "{'kbest__k': (1000, 5000, 10000, 20000, 'all'),\n",
      " 'kbest__score_func': (<function chi2 at 0x1a17c79ea0>,\n",
      "                       <function f_classif at 0x1a17c79d90>),\n",
      " 'sgd__loss': ('hinge', 'log'),\n",
      " 'sgd__penalty': ('l2', 'elasticnet'),\n",
      " 'tfidf__norm': ('l1', 'l2'),\n",
      " 'tfidf__sublinear_tf': (True, False)}\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 101.072s\n",
      "\n",
      "Best score: 0.8457\n",
      "Best parameters set:\n",
      "\tkbest__k: 'all'\n",
      "\tkbest__score_func: <function chi2 at 0x1a17c79ea0>\n",
      "\tsgd__loss: 'hinge'\n",
      "\tsgd__penalty: 'l2'\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__sublinear_tf: True\n"
     ]
    }
   ],
   "source": [
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "# License: BSD 3 clause\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#############################################################################\n",
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('kbest',SelectKBest()),\n",
    "    ('sgd', SGDClassifier(random_state=17)),\n",
    "])\n",
    "\n",
    "# Define the parameters that we want to tune\n",
    "parameters = {\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'tfidf__sublinear_tf': (True, False),\n",
    "    'kbest__score_func':(chi2,f_classif),\n",
    "    'kbest__k': (1000,5000,10000,20000,'all'),\n",
    "    'sgd__penalty': ('l2', 'elasticnet'),\n",
    "    'sgd__loss': ('hinge','log'),\n",
    "}\n",
    "\n",
    "# multiprocessing requires the fork to happen in a __main__ protected  block\n",
    "if __name__ == \"__main__\":\n",
    "    # find the best parameters for both the feature extraction and the classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(sparse_train, sparse_label_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print() \n",
    "    print(\"Best score: %0.4f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter set: {'kbest__k': 'all', 'kbest__score_func': <function chi2 at 0x1a17c79ea0>, 'sgd__loss': 'hinge', 'sgd__penalty': 'l2', 'tfidf__norm': 'l2', 'tfidf__sublinear_tf': True}\n",
      "Accuracy: 0.8457270830152186\n",
      "\n",
      "parameter set: {'kbest__k': 'all', 'kbest__score_func': <function f_classif at 0x1a17c79d90>, 'sgd__loss': 'hinge', 'sgd__penalty': 'l2', 'tfidf__norm': 'l2', 'tfidf__sublinear_tf': True}\n",
      "Accuracy: 0.8457270830152186\n",
      "\n",
      "parameter set: {'kbest__k': 20000, 'kbest__score_func': <function chi2 at 0x1a17c79ea0>, 'sgd__loss': 'hinge', 'sgd__penalty': 'l2', 'tfidf__norm': 'l2', 'tfidf__sublinear_tf': True}\n",
      "Accuracy: 0.8455234895912862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show top 5 optimal parameter sets\n",
    "opt_sets = grid_search.cv_results_ \n",
    "rank_score = opt_sets['rank_test_score']\n",
    "rank_sets = sorted(range(len(rank_score)), key=rank_score.__getitem__)\n",
    "for i in rank_sets[:3]:\n",
    "    print(\"parameter set:\", opt_sets['params'][i])\n",
    "    print(\"Accuracy:\", opt_sets['mean_test_score'][i])\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " # fit model\n",
    "tfidf_opt = TfidfTransformer(norm='l2', sublinear_tf=True).fit(sparse_train)\n",
    "train_opt = tfidf_opt.transform(sparse_train)\n",
    "val_opt = tfidf_opt.transform(sparse_val)\n",
    "test_opt = tfidf_opt.transform(sparse_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* optimal parameter sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train accuracy: 0.8457270106735522\n",
      "validation accuracy: 0.8497803111269445\n"
     ]
    }
   ],
   "source": [
    "sgd_opt = SGDClassifier(loss='hinge', penalty=\"l2\", random_state=17).fit(train_opt, sparse_label_train)\n",
    "print(\"Avg train accuracy:\", cross_val_score(sgd_opt, train_opt, sparse_label_train, cv=5).mean())\n",
    "print(\"validation accuracy:\", sgd_opt.score(val_opt, sparse_label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compare the performance with the parameter sets which remove TF-IDF<br>\n",
    "` to get the parameter sets, you need to run the grid search again and remove line 15,22,23`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanxinyi/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/Users/yuanxinyi/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n",
      "/Users/yuanxinyi/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "kbest_wt = SelectKBest(f_classif, k=5000).fit(train_opt, sparse_label_train)\n",
    "train_wt = kbest_wt.transform(sparse_train)\n",
    "val_wt = kbest_wt.transform(sparse_val)\n",
    "test_wt = kbest_wt.transform(sparse_test_raw)\n",
    "sgd_wt = SGDClassifier(loss='log', penalty='elasticnet', random_state=17).fit(train_wt, sparse_label_train)\n",
    "\n",
    "print(\"Avg train accuracy:\", cross_val_score(sgd_wt, train_wt, sparse_label_train, cv=5).mean())\n",
    "print(\"validation accuracy:\", sgd_wt.score(val_wt, sparse_label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compare the performance with the parameter sets which reduces the features to 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(chi2, k=20000).fit(train_opt, sparse_label_train)\n",
    "train_k = kbest.transform(train_opt)\n",
    "val_k = kbest.transform(val_opt)\n",
    "test_k = kbest.transform(test_opt)\n",
    "sgd_k = SGDClassifier(loss='hinge', penalty=\"l2\", random_state=17).fit(train_k, sparse_label_train)\n",
    "\n",
    "print(\"Avg train accuracy:\", cross_val_score(sgd_k, train_k, sparse_label_train, cv=5).mean())\n",
    "print(\"validation accuracy:\", sgd_k.score(val_k, sparse_label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show default SVC accuracy for comparison\n",
    "svc = LinearSVC().fit(train_opt, sparse_label_train)\n",
    "print(\"Avg train accuracy:\", svc.score( train_opt, sparse_label_train))\n",
    "print(\"validation accuracy:\", svc.score(val_opt, sparse_label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using validation curve to tune optimal C\n",
    "<br>\n",
    "<br>\n",
    "To plot validation_curve, use the code from scikit-learn documentation:\n",
    "<br>\n",
    "\"https://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html#sphx-glr-auto-examples-model-selection-plot-validation-curve-py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = np.logspace(-3, 3, 10)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    LinearSVC(), train_opt, sparse_label_train, param_name=\"C\", param_range=param_range,\n",
    "    cv=5, verbose=1,n_jobs=-1)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"logC\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best C value\n",
    "C_opt = param_range[test_scores_mean.argmax()]\n",
    "print(\"best_C:\",C_opt)\n",
    "svc_opt = LinearSVC(C=C_opt).fit(train_opt,sparse_label_train)\n",
    "\n",
    "print(\"train accuracy:\", svc_opt.score(train_opt, sparse_label_train))\n",
    "print(\"validation accuracy:\", svc_opt.score(val_opt, sparse_label_val))\n",
    "print()\n",
    "# using cv to decrease variance\n",
    "print(\"using 5-fold cross validation:\")\n",
    "print(\"Avg train accuracy:\", cross_val_score(svc_opt, train_opt, sparse_label_train, cv=5).mean())\n",
    "print(\"validation accuracy:\", svc_opt.score(val_opt, sparse_label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#evaluation table\n",
    "svc_prediction = svc_opt.predict(val_opt)\n",
    "print(classification_report(sparse_label_val, svc_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap\n",
    "matric_svc = confusion_matrix(sparse_label_val, svc_prediction)\n",
    "sns.heatmap(matric_svc, annot=True, fmt='d', \n",
    "            xticklabels=['negative','neutral','positive'],yticklabels=['negative','neutral','positive'], cmap='Greens')\n",
    "plt.title('heatmap of confusion matrix for linearSVC')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.yticks(rotation=360)\n",
    "plt.ylabel('Actual class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Adding the votes of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "votes = meta_train.loc[:,['vote_funny','vote_cool','vote_useful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add users's votes into data\n",
    "vote_train, vote_val = train_test_split(votes,test_size=0.3,random_state=17)\n",
    "train_sparse_vote = sparse.hstack((train_opt, vote_train))\n",
    "val_sparse_vote = sparse.hstack((val_opt, vote_val))\n",
    "\n",
    "svc_vote = LinearSVC(C=C_opt).fit(train_sparse_vote,sparse_label_train)\n",
    "print(\"Avg train accuracy:\", cross_val_score(svc_vote, train_sparse_vote, sparse_label_train, cv=5).mean())\n",
    "print(\"validation accuracy:\", svc_vote.score(val_sparse_vote, sparse_label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t0 = time()\n",
    "bagging = BaggingClassifier().fit(train_opt,sparse_label_train)\n",
    "print(\"Avg train accuracy:\", cross_val_score(bagging, train_opt, sparse_label_train, cv=5).mean())\n",
    "print(\"validation accuracy:\", bagging.score(val_opt, sparse_label_val))\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#change base_estimator\n",
    "from time import time\n",
    "t1 = time()\n",
    "bagging = BaggingClassifier(base_estimator= SGDClassifier(loss='hinge', penalty=\"l2\"),random_state=17).fit(train_opt,sparse_label_train)\n",
    "print(\"Avg train accuracy:\", cross_val_score(bagging, train_opt, sparse_label_train, cv=5).mean())\n",
    "print(\"validation accuracy:\", bagging.score(val_opt, sparse_label_val))\n",
    "print(\"done in %0.3fs\" % (time() - t1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Return prediction file to test data for linearSVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use whole training data\n",
    "tfidf_opt = TfidfTransformer(norm='l2', sublinear_tf=True).fit(sparse_train_raw)\n",
    "train_opt = tfidf_opt.transform(sparse_train_raw)\n",
    "test_opt = tfidf_opt.transform(sparse_test_raw)\n",
    "C_opt = param_range[test_scores_mean.argmax()]\n",
    "svc_opt = LinearSVC(C=C_opt).fit(train_opt,labels)\n",
    "pred_result = svc_opt.predict(test_opt)\n",
    "# return prediction csv file\n",
    "test_data = pd.read_csv(\"review_text_test.csv\")\n",
    "output = pd.DataFrame()\n",
    "output['Instance_id']= np.arange(1,len(test_data)+1)\n",
    "output['rating'] = pred_result\n",
    "output.to_csv('test_linearSVC.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Return prediction file to test data for bagging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_opt = TfidfTransformer(norm='l2', sublinear_tf=True).fit(sparse_train_raw)\n",
    "train_opt = tfidf_opt.transform(sparse_train_raw)\n",
    "test_opt = tfidf_opt.transform(sparse_test_raw)\n",
    "pred_result = bagging.predict(test_opt)\n",
    "# return prediction csv file\n",
    "test_data = pd.read_csv(\"review_text_test.csv\")\n",
    "output = pd.DataFrame()\n",
    "output['Instance_id']= np.arange(1,len(test_data)+1)\n",
    "output['rating'] = pred_result\n",
    "output.to_csv('test_bagging.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
